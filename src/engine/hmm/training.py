import json
import os
from dataclasses import dataclass
from os import path
from typing import List, Sequence

from tqdm import trange

from .recognition import RecognizeTask, ResultsFileList
from ..features.feature_sequence import FeatureSequence
from ..files.files import File, FileType
from ..files.lists import FileList
from ..files.tasks import TransformationTask, CreateModelTask
from ..files.tasks import VirtualTransformationTask
from ..helpers import write_lines, write_file, TmpFile, read_file
from ..metadata import metadata_db
from ..settings import BIN_HHEd, BIN_HERest, BIN_HParse, HTK_CONFIGURATION
from ..settings import HEREST_MIN_VARIANCE, TRAINING_ITERATIONS
from ..settings import MODELS_FOLDER
from ..utils import list_arg, list_to_ranges
from ..utils import mkdir, copy, write_mlf, call, write_log

f"""Training

Author: Gilles Waeber <moi@gilleswaeber.ch>, XI 2018
Train the HMM for simple recognition

Usage:
  bm = ...  # A blank model (see feature_extraction.py)
  m = ...  # A trained model
  am = ...  # An audio matching tracks set (see audio.py)
  mixtures = 15  # A number of gaussian mixtures
  iterations = 4 # Training iterations per mixture
  m = bm.train(mixtures, iterations) # Train a model")
  r = m.recognize(am) # Run recognition against a model (see recognize_simple.py)

Shortcuts:
  m = bm.train(mixtures) # Train a model with {TRAINING_ITERATIONS} iterations
"""

# ## Model files
# ## Training artifacts
# List of htk feature files for the testing
MODEL_TRAIN_FEATURES = 'train_features.txt'
# Master label file for the training
MODEL_TRAIN_MLF = 'train.mlf'
# HTK configuration file
MODEL_HTK_CONF = 'htk_conf'
# List of the words
MODEL_WORDS_LIST = 'words.txt'
# Initial MMF file
MODEL_INITIAL_MMF = 'init.mmf'
# Spellings of the words
MODEL_SPELLING = 'spelling.txt'
# BNF Grammar
MODEL_BNF = 'model.bnf'
# Word Network generated by HParse from the BNF
MODEL_WNET = 'model.wnet'


def create_model(src_list: List[File], model_folder, states):
    mkdir(model_folder)
    write_file(f"{model_folder}/files.txt", '\n'.join(f.path() for f in src_list))
    train_features_file = f"{model_folder}/{MODEL_TRAIN_FEATURES}"
    train_mlf_file = f"{model_folder}/{MODEL_TRAIN_MLF}"
    htk_conf_file = f"{model_folder}/{MODEL_HTK_CONF}"
    words_list_file = f"{model_folder}/{MODEL_WORDS_LIST}"
    bnf_file = f"{model_folder}/{MODEL_BNF}"
    wnet_file = f"{model_folder}/{MODEL_WNET}"
    spelling_file = f"{model_folder}/{MODEL_SPELLING}"
    initial_mmf_file = f"{model_folder}/{MODEL_INITIAL_MMF}"

    # Extract bird names
    write_log("Extract bird names")
    bird_names = list(set(f.metadata.label for f in src_list))

    # Extract features count
    write_log("Extract features count")
    features_num = FeatureSequence.from_htk(src_list[0].path()).num_features()

    # Write words list
    write_log(f"Write words list to {words_list_file}")
    write_lines(words_list_file, bird_names)

    # Create BNF
    write_log(f"Write BNF in {bnf_file}")
    with open(bnf_file, 'w') as f:
        f.write(f"$word = {'|'.join(bird_names)} ;\n")
        f.write('( $word )\n')

    # Create word net
    call([BIN_HParse, bnf_file, wnet_file])

    # Write spelling file
    write_log(f"Write spelling in {spelling_file}")
    write_lines(spelling_file,
                (f"{word}\t{' '.join(word.split('-'))}" for word in bird_names))

    # Write features list
    write_log(f"Write features list to {train_features_file}")
    write_lines(train_features_file, (f.path() for f in src_list))

    # Write Master Label File
    write_log(f"Write MLF to {train_mlf_file}")
    write_mlf(dest_file=train_mlf_file, files=src_list)

    # Write HTK config
    write_log(f"Write HTK config to {htk_conf_file}")
    write_file(htk_conf_file, HTK_CONFIGURATION)

    # Create the initial MMF
    write_log(f"Write initial Master Macro File to {initial_mmf_file}")
    hmm_init(initial_mmf_file, features_num, bird_names, states)


def hmm_init(dest_mmf, features_num, bird_names, states):
    """
    Create blank Master Macro File

    See the HTK book 3.4.1 ยง7.3+ยง7.10 for MMF file description
    """

    with open(dest_mmf, "w") as mmf:
        mmf.write("~o\n")  # Global Option Macros
        mmf.write(f"  <StreamInfo> 1 {features_num}\n")  # Stream widths: number of streams and width of each stream
        mmf.write(f"  <VecSize> {features_num}\n")  # Total number of elements for the input vector
        mmf.write("  <nullD>\n")  # No duration vector
        mmf.write("  <user>\n")  # Sample kind: user (the basic one)
        mmf.write("  <DiagC>\n")  # Use a diagonal covariance matrix (why?)

        for name in bird_names:
            mmf.write(f'~h "{name}"\n')  # Physical HMM (ยง7.10 hmmdef, p.125)
            mmf.write("  <BeginHMM>\n")  # HMM definition
            mmf.write(f"    <NumStates> {states}\n")  # Number of states (excl. entry and exit)
            for s in range(2, states):  # Start at 2 (why?)
                mmf.write(f"    <State> {s}\n")
                # Mixture definition (ยง7.10 mixpdf, p.127)
                mmf.write(f"      <Mean> {features_num}\n")
                mmf.write(f"        {f'{1.0 / features_num} ' * features_num}")
                mmf.write(f"      <Variance> {features_num}\n")
                mmf.write(f"        {f'{1.0 / features_num} ' * features_num}")
            mmf.write(f"    <TransP> {states}\n")  # Transition matrix
            for row in range(states):
                mmf.write("      ")
                for col in range(states):
                    if row == 0 and col == 1:
                        mmf.write("1.0 ")
                    elif (0 < row < states - 1) and (row == col or row == col - 1):
                        mmf.write("0.5 ")
                    else:
                        mmf.write("0.0 ")
                mmf.write("\n")
            mmf.write("  <EndHMM>\n")


def train_model(model_folder, mixtures, iterations, herest_min_variance):
    """Train the HMM"""
    train_features_file = f"{model_folder}/{MODEL_TRAIN_FEATURES}"
    initial_mmf_file = f"{model_folder}/{MODEL_INITIAL_MMF}"
    # HTK configuration file
    htk_conf_file = f"{model_folder}/{MODEL_HTK_CONF}"
    # List of the words
    words_list_file = f"{model_folder}/{MODEL_WORDS_LIST}"
    # Master label file for the training
    train_mlf_file = f"{model_folder}/{MODEL_TRAIN_MLF}"

    def mmf_path(m, i):
        return f"{model_folder}/trained_g{m}_t{i}_{iterations}.mmf"

    for m in trange(1, mixtures + 1):
        if path.isfile(mmf_path(m, iterations)):
            continue

        # MultiGaussian HHed file
        current_mu_file = f"{model_folder}/mu_{m}.hhed"
        with TmpFile(mmf_path(m, 0)) as new_mmf_file:
            previous_mmf_file = initial_mmf_file if m == 1 else mmf_path(m - 1, iterations)
            copy(previous_mmf_file, new_mmf_file)

            write_file(current_mu_file, f"MU {m} {{*.state[2-10000].mix}}")

            # Add a new mixture
            call([
                BIN_HHEd,
                '-C', htk_conf_file,
                '-M', f"{model_folder}/",
                '-H', new_mmf_file,
                current_mu_file,
                words_list_file
            ])

        for i in range(iterations):
            current_mmf_file = mmf_path(m, i + 1)
            if path.isfile(current_mmf_file):
                continue
            with TmpFile(current_mmf_file) as out:
                copy(mmf_path(m, i), out)
                call([
                    BIN_HERest,
                    '-C', htk_conf_file,
                    '-v', "{:g}".format(herest_min_variance),
                    '-M', f"{model_folder}/",
                    '-I', train_mlf_file,
                    '-H', out,
                    '-s', out,
                    '-S', train_features_file, words_list_file
                ])
        for i in range(iterations):
            os.remove(mmf_path(m, i))


@dataclass(frozen=True)
class HMMModel:
    files: Sequence[File]
    states: int


class CreateHMMModelTask(CreateModelTask):

    def __init__(self, src_list, name, states):
        states = list_arg(states)
        self.states = states
        super().__init__(src_list, BlankModelFileList([
            File(f"{MODELS_FOLDER}/hmm/{name}/s{s}/{src_list.features_digest()}",
                 "init.mmf", task_src=HMMModel(src_list.files, s), metadata=metadata_db(src_list.files))
            for s in sorted(states, reverse=True)
            # Reverse sorting to start training models with the most states first with parallel processing
        ], self), {'name': name, 'states': states}, name)
        self.states = states

    def __str__(self):
        return f"Create initial HMM Model with {self.states} states"

    def run_file(self, file):
        mkdir(file.folder)
        write_file(file.p.parent / 'files.txt', self.src_list.files_digest_string())
        create_model(file.task_src.files, file.folder, file.task_src.states)


class TrainModelTask(TransformationTask):
    def __init__(self, src_list, mixtures, iterations):
        super().__init__(src_list, ModelFileList([
            File(f.folder, f"trained_g{mixtures}_t{iterations}_{iterations}.mmf", f) for f in src_list.files
        ], self), {'mixtures': mixtures, 'iterations': iterations})

    def __str__(self):
        return (
            f"Train the model with {self.props['mixtures']} gaussian mixtures "
            f"and {self.props['iterations']} training iterations")

    def run(self, missing, *, parallel=None):
        self.src_list.run(parallel=parallel)
        super().run(missing, parallel=parallel)

    def run_file(self, file: File):
        mkdir(file.folder)
        train_model(file.folder, self.props['mixtures'], self.props['iterations'], HEREST_MIN_VARIANCE)
        write_file(f"{file.path()}.json", json.dumps(self.export(), indent=2))


def _call_acc_get(el):
    el['acc'] = el['acc'].get()['accuracy']
    return el


class EvaluateModelTask(TransformationTask):
    def __init__(self, src_list, validate, mixtures):
        if validate.type == FileType.AUDIO:
            validate = validate.preproc_from(src_list)
        assert validate.type == FileType.FEATURES
        self.validate = validate
        self.mixtures = mixtures
        self.parallel = None
        super().__init__(src_list, EvaluatedModelFileList([
            File(l.files[0].p.with_name(f'stats_{validate.features_digest()}_m{list_to_ranges(mixtures)}.json'), task_src=l)
            for l in src_list.separate()
        ], self), dict(mixtures=mixtures, validate=validate.task.export()))

    def run(self, missing, *, parallel=None):
        self.src_list.train(max(self.mixtures)).run(parallel=parallel)
        self.parallel = parallel
        super().run(missing, parallel=None)

    def run_file(self, file: File):
        stats = [dict(mixtures=m, acc=file.task_src.train(m).recognize(self.validate)) for m in self.mixtures]
        if self.parallel is not None:
            stats = self.parallel.map(_call_acc_get, stats)
            self.parallel = None
        else:
            stats = [_call_acc_get(e) for e in stats]

        write_file(file.p, json.dumps(stats))


class ChooseModelTask(VirtualTransformationTask):
    def __init__(self, src_list, states, mixtures):
        states_model = dict((f.task_src.task.states[0], f.task_src) for f in src_list.files)
        super().__init__(src_list, ModelFileList(
            states_model[states].train(mixtures).files
            , self), dict(states=states, mixtures=mixtures))


class ModelFileList(FileList):
    type = FileType.MODEL

    def __init__(self, files, task=None):
        super().__init__(files, task)

    def recognize(self, validate) -> ResultsFileList:
        task = RecognizeTask(self, validate)
        return task.dest_list


class BlankModelFileList(FileList):
    type = FileType.BLANK_MODEL

    def train(self, mixtures) -> ModelFileList:
        iterations = TRAINING_ITERATIONS
        task = TrainModelTask(self, mixtures, iterations)
        return task.dest_list

    def evaluate_model(self, validate, mixtures):
        task = EvaluateModelTask(self, validate, mixtures)
        return task.dest_list

    def separate(self):
        parts = [
            self.task.src_list.create_hmm_model(self.task.name, s) for s in self.task.states
        ]
        for e in parts:
            e.has_been_processed = self.has_been_processed
        return parts


class EvaluatedModelFileList(FileList):
    type = FileType.EVALUATION

    def get_best(self, *, parallel=None):
        self.run(parallel=parallel)
        assert all(len(f.task_src.task.states) == 1 for f in self.files), "Separation problem"
        stats = [(f.task_src.task.states[0], json.loads(read_file(f.p))) for f in self.files]
        stats = [dict(states=s, **info) for s, l in stats for info in l]
        return sorted(stats, key=lambda s: (-s['acc'], s['states'], s['mixtures']))[0]

    def recognize_best_val_acc(self, testing, *, parallel=None):
        best = self.get_best(parallel=parallel)
        task = ChooseModelTask(self, best['states'], best['mixtures'])
        return task.dest_list.recognize(testing)
